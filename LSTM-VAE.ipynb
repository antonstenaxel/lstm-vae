{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, LSTM, RepeatVector, CuDNNLSTM\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import objectives\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('absolute_interpolated_data.npy')[:,:,:2] #Data generated by preprocessing script\n",
    "\n",
    "# Check if data contains nan\n",
    "if np.isnan(data).any():\n",
    "    print(\"Data contains nan values\")\n",
    "\n",
    "print(\"size: \",data.nbytes/1e6, 'MB')\n",
    "print('shape:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some hyperparameters\n",
    "\n",
    "n_datapoints, timesteps, input_dim = data.shape\n",
    "\n",
    "batch_size  = 500\n",
    "intermediate_dim  = 512\n",
    "latent_dim = 64\n",
    "epsilon_std= 1\n",
    "beat = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_input = Input(shape=(timesteps, input_dim,))\n",
    "\n",
    "# LSTM encoding\n",
    "encoder_layer = CuDNNLSTM(intermediate_dim, return_sequences=True)(vae_input)\n",
    "encoder_layer = CuDNNLSTM(intermediate_dim)(encoder_layer)\n",
    "\n",
    "# VAE Z layer\n",
    "z_mean = Dense(latent_dim)(encoder_layer)\n",
    "z_log_sigma = Dense(latent_dim)(encoder_layer)\n",
    "\n",
    "z = Lambda(sample_z, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "# decoded LSTM layer\n",
    "decoder_layer_1 = CuDNNLSTM(intermediate_dim, return_sequences=True)\n",
    "decoder_layer_2 = CuDNNLSTM(intermediate_dim, return_sequences=True)\n",
    "\n",
    "decoder_output = LSTM(input_dim, return_sequences=True, activation = None)\n",
    "\n",
    "\n",
    "decoded_layer = RepeatVector(timesteps)(z)\n",
    "decoded_layer = decoder_layer_1(decoded_layer)\n",
    "decoded_layer = decoder_layer_2(decoded_layer)\n",
    "\n",
    "\n",
    "# decoded layer\n",
    "vae_output = decoder_output(decoded_layer)\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(vae_input, vae_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder, from inputs to latent space\n",
    "encoder_output_mean = z_mean\n",
    "encoder_output_std = Lambda(K.exp)(z_log_sigma)\n",
    "encoder = Model(vae_input, [encoder_output_mean, encoder_output_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "_decoded_layer = RepeatVector(timesteps)(decoder_input)\n",
    "_decoded_layer = decoder_layer_1(_h_decoded)\n",
    "_decoded_layer = decoder_layer_2(_h_decoded)\n",
    "\n",
    "decoder_output = decoder_output(_h_decoded)\n",
    "\n",
    "generator = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(x, x_decoded_mean):\n",
    "    cross_entropy = objectives.mse(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "    loss = cross_entropy + beta*kl_loss\n",
    "    return loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=loss_function)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [ReduceLROnPlateau(patience = 5)]\n",
    "\n",
    "history = vae.fit(x = data, \n",
    "                  y = data,\n",
    "                  validation_split= 0.1,\n",
    "                  batch_size=batch_size, \n",
    "                  epochs = 100,\n",
    "                  callbacks = cb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.save_weights('vae_weights.hdf5')\n",
    "decoder.save_weights('decoder_weights.hdf5')\n",
    "encoder.save_weights('encoder_weights.hdf5')\n",
    "np.save('history_final_training.npy',history.history)\n",
    "np.save('final_preds_train.npy', vae_output)\n",
    "np.save('final_labels_train.npy', labels[:batch_size])\n",
    "np.save('final_preds.npy', vae_output)\n",
    "np.save('final_labels.npy', labels[:batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 50\n",
    "dp = vae_output[d]\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "x_output = dp[:,0]\n",
    "y_output = dp[:,1]\n",
    "x_input = p_data[d,:,0]\n",
    "y_input = p_data[d,:,1]\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for x, y in zip(x_input[::2], y_input[::2]):\n",
    "    ax[0].text(x+0.1, y+0.1, str(i), color=\"black\", fontsize=12)\n",
    "    i+=1\n",
    "    \n",
    "ax[0].plot(x_input, y_input,'ko', markersize = 4)\n",
    "ax[0].axis('equal')\n",
    "ax[0].axis('off')\n",
    "\n",
    "i = 0\n",
    "for x, y in zip(x_output[::2], y_output[::2]):\n",
    "    ax[1].text(x+0.1, y+0.1, str(i), color=\"black\", fontsize=12)\n",
    "    i+=1\n",
    "\n",
    "ax[1].plot(x_output, y_output,'bo', markersize = 4)\n",
    "ax[1].axis('equal')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot multiple decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_data = data[-batch_size:,:,:]\n",
    "vae_output = vae.predict(data[-batch_size:,:,:], batch_size = batch_size)\n",
    "# Read the labels from trainlabels.txt and testlabels.txt in the sequences directory\n",
    "dataset_dir = os.path.abspath('sequences') # Name of your sequences folder\n",
    "labels_file = os.path.join(dataset_dir, 'trainlabels.txt')\n",
    "f = open(labels_file)\n",
    "train_labels = np.array([int(x) for x in f.read().split()])\n",
    "f.close()\n",
    "labels_file = os.path.join(dataset_dir, 'testlabels.txt')\n",
    "f = open(labels_file)\n",
    "test_labels = np.array([int(x) for x in f.read().split()])\n",
    "labels = np.concatenate((train_labels, test_labels))\n",
    "\n",
    "# Input to this code section\n",
    "# variables\n",
    "# `labels`     - the correct labels of the data in variable `data`\n",
    "# `data`       - the preprocessed data\n",
    "# `vae_output` - the outputs generated by the VAE when feeding `data` to the network\n",
    "# `dp_inds`    - select a subset of indices to plot (type: list or tuple)\n",
    "\n",
    "#vae_output = data\n",
    "dp_inds = range(20,28)\n",
    "\n",
    "axis_max = 3\n",
    "axis_min = -3\n",
    "n_rows = math.ceil(len(dp_inds) / 2)\n",
    "fig, axs = plt.subplots(n_rows, 4, figsize=(20, 5*n_rows))\n",
    "for i, di in enumerate(dp_inds):\n",
    "    ax_row = i // 2\n",
    "    ax_col = 0 if i % 2 == 0 else 2\n",
    "   # plot_indices = []\n",
    "   # for j in range(data.shape[1]):\n",
    "   #     plot_indices.append(np.any(np.abs(data[di,j,[0,1]]) > 1e-4))\n",
    "    \n",
    "    axs[ax_row, ax_col].plot(p_data[di,:,0], p_data[di,:,1],'ko', markersize = 5)\n",
    "    axs[ax_row, ax_col].axis('equal')\n",
    "    axs[ax_row, ax_col].set_xlim(axis_min, axis_max)\n",
    "    axs[ax_row, ax_col].set_ylim(axis_min, axis_max)\n",
    "    axs[ax_row, ax_col].grid(True)\n",
    "    axs[ax_row, ax_col].set_title(\"Input to VAE digit {}\".format(labels[di]))\n",
    "    axs[ax_row, ax_col].axis('off')\n",
    "    axs[ax_row, ax_col + 1].plot(vae_output[di,:,0], vae_output[di,:,1],'bo', markersize = 5)\n",
    "    axs[ax_row, ax_col + 1].axis('equal')\n",
    "    axs[ax_row, ax_col + 1].set_xlim(axis_min, axis_max)\n",
    "    axs[ax_row, ax_col + 1].set_ylim(axis_min, axis_max)\n",
    "    axs[ax_row, ax_col + 1].grid(True)\n",
    "    axs[ax_row, ax_col + 1].set_title(\"VAE generated digit {}\".format(labels[di]))\n",
    "    axs[ax_row, ax_col + 1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = 0\n",
    "d2 = 15\n",
    "\n",
    "h1 = encoder.predict(data[d1:d1+1])\n",
    "z1 = h1[0] + h1[1]*np.random.randn(64)\n",
    "h2 = encoder.predict(data[d2:d2+1])\n",
    "z2 = h2[0] + h2[1]*np.random.randn(64)\n",
    "\n",
    "\n",
    "n = 10\n",
    "alpha = np.linspace(0,1, num=n)\n",
    "target = np.zeros((n,64))\n",
    "\n",
    "for i in range(n):\n",
    "    target[i,:] = (1-alpha[i])*z1 + alpha[i]*z2\n",
    "\n",
    "outputs = np.zeros((n,60,2))\n",
    "for i in range(n):\n",
    "    seq = decoder.predict(target[i:i+1,:])\n",
    "    outputs[i,:,:] = seq\n",
    "    \n",
    "fig, axes = plt.subplots(1,n, figsize = (15,5))\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "for i in range(n):\n",
    "    ax = axes[i]\n",
    "    ax.plot(outputs[i,:,0], outputs[i,:,1],'ko')\n",
    "    ax.axis('equal')\n",
    "    ax.axis('off')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample multiple ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = 21\n",
    "\n",
    "h1 = encoder.predict(data[d1:d1+1])\n",
    "\n",
    "fig, axes = plt.subplots(1,5)\n",
    "\n",
    "for i in range(5):\n",
    "    z1 = h1[0] + h1[1]*2*np.random.randn(64)\n",
    "    seq = decoder.predict(z1)\n",
    "    \n",
    "    x_output = seq[0,:,0]\n",
    "    y_output = seq[0,:,1]\n",
    "    j = 0\n",
    "    \n",
    "    axes[i].plot(x_output, y_output,'ko', markersize = 4)\n",
    "    axes[i].axis('equal')\n",
    "    axes[i].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
